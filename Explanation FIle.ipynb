{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages such as numpy,CV2 and collections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection Module in Python provides different types of containers. A Container is an object that is used to store different objects and provide a way to access the contained objects and iterate over them. Some of the built-in containers are Tuple, List, Dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deque (Doubly Ended Queue) is the optimized list for quicker append and pop operations from both sides of the container. It provides O(1) time complexity for append and pop operations as compared to list with O(n) time complexity. \n",
    "**Syntax - class collections.deque(list)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a trackbar, first we have to create the window\n",
    "in which it is going to be located. \n",
    "\n",
    "**namedWindow(\"Linear Blend\", WINDOW_AUTOSIZE); // Create Window**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the Trackbar:\n",
    "\n",
    "**cv.createTrackbar(trackbar_name, title_window , 0, alpha_slider_max, on_trackbar)**\n",
    "\n",
    "Note the following (C++ code):\n",
    "- Our Trackbar has a label TrackbarName\n",
    "- The Trackbar is located in the window named Linear\n",
    "Blend\n",
    "- The Trackbar values will be in the range from 0 to alpha_slider_max (the minimum limit is always zero).\n",
    "- The numerical value of Trackbar is stored in alpha_slider\n",
    "- Whenever the user moves the Trackbar, the callback function on_trackbar is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default called trackbar function \n",
    "def setValues(x):\n",
    "   print(\"\")\n",
    "\n",
    "# Creating the trackbars needed for adjusting the marker colour\n",
    "cv2.namedWindow(\"Color detectors\")\n",
    "cv2.createTrackbar(\"Upper Hue\", \"Color detectors\", 153, 180,setValues)\n",
    "cv2.createTrackbar(\"Upper Saturation\", \"Color detectors\", 255, 255,setValues)\n",
    "cv2.createTrackbar(\"Upper Value\", \"Color detectors\", 255, 255,setValues)\n",
    "cv2.createTrackbar(\"Lower Hue\", \"Color detectors\", 64, 180,setValues)\n",
    "cv2.createTrackbar(\"Lower Saturation\", \"Color detectors\", 72, 255,setValues)\n",
    "cv2.createTrackbar(\"Lower Value\", \"Color detectors\", 49, 255,setValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving different arrays to handle colour points of different colour\n",
    "bpoints = [deque(maxlen=1024)]\n",
    "gpoints = [deque(maxlen=1024)]\n",
    "rpoints = [deque(maxlen=1024)]\n",
    "ypoints = [deque(maxlen=1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These indexes will be used to mark the points in particular arrays of specific colour\n",
    "blue_index = 0\n",
    "green_index = 0\n",
    "red_index = 0\n",
    "yellow_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theory-\n",
    "\n",
    "Morphological transformations are some simple operations based on the image shape. It is normally performed on binary images. It needs two inputs, one is our original image, second one is called structuring element or kernel which decides the nature of operation. Two basic morphological operators are Erosion and Dilation. Then its variant forms like Opening, Closing, Gradient etc also comes into play.\n",
    "\n",
    "1. **Erosion**\n",
    "\n",
    "The basic idea of erosion is just like soil erosion only, it erodes away the boundaries of foreground object (Always try to keep foreground in white). So what does it do? The kernel slides through the image (as in 2D convolution). A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "\n",
    "So what happends is that, all the pixels near boundary will be discarded depending upon the size of kernel. So the thickness or size of the foreground object decreases or simply white region decreases in the image. It is useful for removing small white noises (as we have seen in colorspace chapter), detach two connected objects etc.\n",
    "\n",
    "Here, as an example, I would use a 5x5 kernel with full of ones. Let’s see it how it works:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('j.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "2. **Dilation**\n",
    "\n",
    "It is just opposite of erosion. Here, a pixel element is ‘1’ if atleast one pixel under the kernel is ‘1’. So it increases the white region in the image or size of foreground object increases. Normally, in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object. So we dilate it. Since noise is gone, they won’t come back, but our object area increases. It is also useful in joining broken parts of an object.\n",
    "\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "3. **Opening**\n",
    "\n",
    "Opening is just another name of erosion followed by dilation. It is useful in removing noise, as we explained above. Here we use the function, cv2.morphologyEx()\n",
    "\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "LINK to the Dialation/Erosion - [Morphological Operations](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The kernel to be used for dialation purpose.\n",
    "kernel = np.ones((5,5),np.unit8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = R G B Y\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (0, 255, 255)]\n",
    "colorIndex = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "void cv::rectangle(  InputOutputArray img,\n",
    "\n",
    "                     Point pt1,\n",
    "                     \n",
    "                     Point pt2,\n",
    "                     \n",
    "                     const&Scalar color,\n",
    "                     \n",
    "                     int thickness = 1,\n",
    "                     \n",
    "                     int lineType = LINE_8,\n",
    "                     \n",
    "                     int shift = 0)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draws a simple, thick, or filled up-right rectangle.\n",
    "\n",
    "The function cv::rectangle draws a rectangle outline or a filled rectangle whose two opposite corners are pt1 and pt2.\n",
    "\n",
    "Parameters\n",
    "- img:\tImage.\n",
    "- pt1:\tVertex of the rectangle.\n",
    "- pt2:\tVertex of the rectangle opposite to pt1 .\n",
    "- color:\tRectangle color or brightness (grayscale image).\n",
    "- thickness:\tThickness of lines that make up the rectangle. Negative values, like FILLED, mean that the      function has to draw a filled rectangle.\n",
    "- lineType:\tType of the line. See LineTypes\n",
    "- shift:\tNumber of fractional bits in the point coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is code for Canvas setup\n",
    "paintWindow = np.zeros((471,636,3)) + 255\n",
    "paintWindow = cv2.rectangl11e(paintWindow, (40,1), (140,65), (0,0,0), 2)\n",
    "paintWindow = cv2.rectangle(paintWindow, (160,1), (255,65), colors[0], -1)\n",
    "paintWindow = cv2.rectangle(paintWindow, (275,1), (370,65), colors[1], -1)\n",
    "paintWindow = cv2.rectangle(paintWindow, (390,1), (485,65), colors[2], -1)\n",
    "paintWindow = cv2.rectangle(paintWindow, (505,1), (600,65), colors[3], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV-Python is a library of Python bindings designed to solve computer vision problems. cv2.putText() method is used to draw a text string on any image.\n",
    "\n",
    "Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "Parameters:\n",
    "- image: It is the image on which text is to be drawn.\n",
    "- text: Text string to be drawn.\n",
    "- org: It is the coordinates of the bottom-left corner of the text     string in the image. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "- font: It denotes the font type. Some of font types are FONT_HERSHEY_SIMPLEX, FONT_HERSHEY_PLAIN, , etc.\n",
    "- fontScale: Font scale factor that is multiplied by the font-specific base size.\n",
    "- color: It is the color of text string to be drawn. For BGR, we pass a tuple. eg: (255, 0, 0) for blue color.\n",
    "- thickness: It is the thickness of the line in px.\n",
    "- lineType: This is an optional parameter.It gives the type of the line to be used.\n",
    "- bottomLeftOrigin: This is an optional parameter. When it is true, the image data origin is at the bottom-left corner. Otherwise, it is at the top-left corner.\n",
    "\n",
    "Return Value: It returns an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(paintWindow, \"CLEAR\", (49, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"BLUE\", (185, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"GREEN\", (298, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"RED\", (420, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"YELLOW\", (520, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150,150,150), 2, cv2.LINE_AA)\n",
    "cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link for VideoCapture - [LINK](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the default webcam of PC.\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
